{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e957947-e5a9-4008-bdc1-3df46f3a07df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting igraph\n",
      "  Downloading igraph-0.11.8-cp39-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting texttable>=1.6.2 (from igraph)\n",
      "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Downloading igraph-0.11.8-cp39-abi3-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: texttable, igraph\n",
      "Successfully installed igraph-0.11.8 texttable-1.7.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Fetched 25461 profiles and 2505 connections.\n"
     ]
    }
   ],
   "source": [
    "!pip install igraph\n",
    "import sqlite3\n",
    "import networkx as nx\n",
    "\n",
    "# --- Database Connection and Data Retrieval ---\n",
    "\n",
    "db_path = \"social_network_anonymized.db\"  # Replace with your actual path\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Fetch Profiles (all, for later use)\n",
    "cursor.execute(\"SELECT id, name, profile_type, profile_url FROM Profiles\")\n",
    "all_profiles = [\n",
    "    {\"id\": row[0], \"name\": row[1], \"profile_type\": row[2], \"profile_url\": row[3]}\n",
    "    for row in cursor.fetchall()\n",
    "]\n",
    "\n",
    "# Fetch Profile Connections (focus on relevant connection types)\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT source_id, target_id, connection_type\n",
    "    FROM ProfileConnection\n",
    "    WHERE connection_type IN ('BECAME_MEMBER_OF_GROUP_ON_FACEBOOK', 'INTERACTED_IN_THE_CONTEXT_OF_ON_FACEBOOK')\n",
    "\"\"\")\n",
    "profile_connections = [\n",
    "    {\"source_id\": row[0], \"target_id\": row[1], \"connection_type\": row[2]}\n",
    "    for row in cursor.fetchall()\n",
    "]\n",
    "\n",
    "conn.close()  # Close the database connection\n",
    "\n",
    "print(f\"Fetched {len(all_profiles)} profiles and {len(profile_connections)} connections.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afd95b5a-269d-4039-80b2-35f596d4826e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: igraph in /Users/unknowit/miniconda3/envs/ML/lib/python3.11/site-packages (0.11.8)\n",
      "Requirement already satisfied: texttable>=1.6.2 in /Users/unknowit/miniconda3/envs/ML/lib/python3.11/site-packages (from igraph) (1.7.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Fetched 25461 profiles, 102738 activities.\n",
      "Prepared 83584 profile-activity edges and 43380 profile-connection edges.\n",
      "Removed 45957 isolated vertices.\n",
      "Graph now has 82242 vertices and 126964 edges.\n"
     ]
    }
   ],
   "source": [
    "!pip install igraph\n",
    "import sqlite3\n",
    "import igraph as ig\n",
    "\n",
    "# --- Database Connection ---\n",
    "db_path = \"social_network_anonymized.db\"  # !!! Replace with your actual path !!!\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# --- Data Retrieval ---\n",
    "\n",
    "# 1. Fetch Profiles\n",
    "cursor.execute(\"SELECT id, name, profile_type FROM Profiles\")\n",
    "profiles = [\n",
    "    {\"id\": row[0], \"name\": row[1], \"type\": row[2], \"node_type\": \"profile\"}\n",
    "    for row in cursor.fetchall()\n",
    "]\n",
    "\n",
    "# 2. Profile ID to Vertex Index Mapping\n",
    "profile_id_to_index = {profile[\"id\"]: i for i, profile in enumerate(profiles)}\n",
    "\n",
    "# 3. Fetch Activities\n",
    "cursor.execute(\"SELECT id, type, content, description, timestamp FROM Activity\")\n",
    "activities = [\n",
    "    {\"id\": row[0], \"type\": row[1], \"content\": row[2], \"description\": row[3], \"timestamp\": row[4], \"node_type\": \"activity\"}\n",
    "    for row in cursor.fetchall()\n",
    "]\n",
    "\n",
    "# 4. Activity ID to Vertex Index Mapping\n",
    "activity_id_to_index = {activity[\"id\"]: i + len(profiles) for i, activity in enumerate(activities)}  # Offset\n",
    "\n",
    "# 5. Fetch Profile-Activity Relationships (handling 'creator')\n",
    "#  AND get timestamp directly in this query!\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT pa.profile_id, pa.activity_id, pa.relationship_type, a.timestamp\n",
    "    FROM ProfileActivity pa\n",
    "    JOIN Activity a ON pa.activity_id = a.id\n",
    "\"\"\")  # Much more efficient!\n",
    "profile_activity_edges = []\n",
    "for row in cursor.fetchall():\n",
    "    profile_id, activity_id, rel_type, timestamp = row  # Unpack all four values\n",
    "\n",
    "    if profile_id not in profile_id_to_index:\n",
    "        continue\n",
    "    if activity_id not in activity_id_to_index:\n",
    "        continue\n",
    "\n",
    "    if rel_type == \"source\" or rel_type == \"creator\":\n",
    "        # Profile -> Activity  (add timestamp here)\n",
    "        profile_activity_edges.append(((profile_id_to_index[profile_id], activity_id_to_index[activity_id]), timestamp))\n",
    "    elif rel_type == \"target\":\n",
    "        # Activity -> Profile (add timestamp here)\n",
    "        profile_activity_edges.append(((activity_id_to_index[activity_id], profile_id_to_index[profile_id]), timestamp))\n",
    "    # Ignore other relationship types\n",
    "\n",
    "\n",
    "# 6. Fetch Profile Connections\n",
    "cursor.execute(\"SELECT source_id, target_id, connection_type FROM ProfileConnection\")\n",
    "profile_connection_edges = []\n",
    "for row in cursor.fetchall():\n",
    "    source_id = row[0]\n",
    "    target_id = row[1]\n",
    "\n",
    "    if source_id not in profile_id_to_index:\n",
    "        continue\n",
    "    if target_id not in profile_id_to_index:\n",
    "        continue\n",
    "\n",
    "    # Profile -> Profile (no timestamp here, unless your ProfileConnection table *has* a timestamp)\n",
    "    profile_connection_edges.append(((profile_id_to_index[source_id], profile_id_to_index[target_id]), None))  # Add None for consistency\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(f\"Fetched {len(profiles)} profiles, {len(activities)} activities.\")\n",
    "print(f\"Prepared {len(profile_activity_edges)} profile-activity edges and {len(profile_connection_edges)} profile-connection edges.\")\n",
    "\n",
    "# --- Build the igraph Graph ---\n",
    "\n",
    "# No longer combine edges *before* adding them.  We need to add the timestamp to each edge.\n",
    "graph = ig.Graph(directed=True)\n",
    "graph.add_vertices(len(profiles) + len(activities))\n",
    "\n",
    "# Set Vertex Attributes (Profiles)\n",
    "for profile in profiles:\n",
    "    vertex_index = profile_id_to_index[profile[\"id\"]]\n",
    "    graph.vs[vertex_index][\"name\"] = profile[\"name\"]\n",
    "    graph.vs[vertex_index][\"type\"] = profile[\"type\"]\n",
    "    graph.vs[vertex_index][\"node_type\"] = profile[\"node_type\"]\n",
    "    graph.vs[vertex_index][\"original_id\"] = profile[\"id\"]\n",
    "\n",
    "# Set Vertex Attributes (Activities)\n",
    "for activity in activities:\n",
    "    vertex_index = activity_id_to_index[activity[\"id\"]]\n",
    "    graph.vs[vertex_index][\"name\"] = f\"Activity_{activity['id']}\"\n",
    "    graph.vs[vertex_index][\"type\"] = activity[\"type\"]\n",
    "    graph.vs[vertex_index][\"node_type\"] = activity[\"node_type\"]\n",
    "    graph.vs[vertex_index][\"original_id\"] = activity[\"id\"]\n",
    "\n",
    "# Add edges *with* timestamps\n",
    "for edge, timestamp in profile_activity_edges:\n",
    "    graph.add_edge(edge[0], edge[1], timestamp=timestamp)\n",
    "\n",
    "for edge, timestamp in profile_connection_edges:  # 'timestamp' will often be None here.\n",
    "    graph.add_edge(edge[0], edge[1], timestamp=timestamp)  #Add timestamps here.\n",
    "\n",
    "\n",
    "# --- Remove Isolated Nodes ---\n",
    "\n",
    "# Get the indices of vertices with degree 0\n",
    "isolated_vertices = [v.index for v in graph.vs if v.degree() == 0]\n",
    "\n",
    "# Delete those vertices\n",
    "graph.delete_vertices(isolated_vertices)\n",
    "\n",
    "print(f\"Removed {len(isolated_vertices)} isolated vertices.\")\n",
    "print(f\"Graph now has {graph.vcount()} vertices and {graph.ecount()} edges.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c208902-5db8-4de2-b0aa-5d22de5cb90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BAD_PROFILE_IDS = [23381, 23387, 23412, 23539]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18c4c21f-55f5-4d7a-8d4c-b10998a175c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: -3600000, max: 1714533722000\n"
     ]
    }
   ],
   "source": [
    "bad_profile_ids = [23381, 23387, 23412, 23539]\n",
    "training_cutoff_timestamp = 1714533722000  #  This is when 75% of activity has been made\n",
    "'''WITH OrderedActivity AS (\n",
    "    SELECT timestamp, \n",
    "           ROW_NUMBER() OVER (ORDER BY timestamp) AS row_num,\n",
    "           COUNT(*) OVER () AS total_rows\n",
    "    FROM Activity\n",
    ")\n",
    "SELECT timestamp \n",
    "FROM OrderedActivity\n",
    "WHERE row_num = CEIL(total_rows * 0.75)  -- 75th percentile row\n",
    "LIMIT 1;'''\n",
    "# into a reasonable training/testing period.\n",
    "\n",
    "# --- 1. Create Training and Testing Subgraphs ---\n",
    "\n",
    "training_edges = [edge.index for edge in graph.es if edge[\"timestamp\"] is not None and edge[\"timestamp\"] <= training_cutoff_timestamp]\n",
    "testing_edges = [edge.index for edge in graph.es if edge[\"timestamp\"] is not None and edge[\"timestamp\"] > training_cutoff_timestamp]\n",
    "\n",
    "training_graph = graph.subgraph_edges(training_edges, delete_vertices=False)\n",
    "testing_graph = graph.subgraph_edges(testing_edges, delete_vertices=False)\n",
    "\n",
    "# Remove isolated nodes in the training graph.\n",
    "training_graph.delete_vertices([v.index for v in training_graph.vs if v.degree() == 0])\n",
    "\n",
    "\n",
    "# --- 2. Feature Engineering (Training Period) ---\n",
    "#Find min and max of timestamps\n",
    "min_timestamp = float('inf')\n",
    "max_timestamp = float('-inf')\n",
    "for edge in training_graph.es:\n",
    "  if 'timestamp' in edge.attributes():\n",
    "    timestamp = edge['timestamp']\n",
    "    if timestamp < min_timestamp:\n",
    "      min_timestamp = timestamp\n",
    "    if timestamp > max_timestamp:\n",
    "      max_timestamp = timestamp\n",
    "print(f\"min: {min_timestamp}, max: {max_timestamp}\")\n",
    "features = []\n",
    "profile_ids_list = []\n",
    "\n",
    "#Iterate through profiles in the training graph.\n",
    "for profile_vertex in training_graph.vs:\n",
    "    if profile_vertex[\"node_type\"] == \"profile\" and profile_vertex[\"original_id\"] not in bad_profile_ids: #check not bad\n",
    "\n",
    "        profile_id = profile_vertex[\"original_id\"]\n",
    "        profile_ids_list.append(profile_id) #add profile ids\n",
    "\n",
    "        # --- Network Features ---\n",
    "        degree = training_graph.degree(profile_vertex.index)\n",
    "        in_degree = training_graph.indegree(profile_vertex.index)\n",
    "        out_degree = training_graph.outdegree(profile_vertex.index)\n",
    "        clustering_coefficient = training_graph.transitivity_local_undirected(profile_vertex.index, mode=\"zero\") # Handles 0 division\n",
    "        #pagerank = training_graph.pagerank(profile_vertex.index) # PageRank\n",
    "        #betweenness = training_graph.betweenness(profile_vertex.index) # Betweeness\n",
    "        #Get good neighbours\n",
    "        good_neighbors = 0 # Number of neighboring profiles that are not \"bad\"\n",
    "        for neighbor_index in training_graph.neighbors(profile_vertex.index):\n",
    "            if training_graph.vs[neighbor_index][\"node_type\"] == \"profile\" and training_graph.vs[neighbor_index][\"original_id\"] not in bad_profile_ids:\n",
    "                good_neighbors +=1\n",
    "\n",
    "        # --- Activity Features ---\n",
    "        num_activities = 0\n",
    "        for edge in training_graph.es:\n",
    "            if edge.source == profile_vertex.index or edge.target == profile_vertex.index:\n",
    "                num_activities +=1\n",
    "\n",
    "        # Example: Activity rate (activities per day).\n",
    "        #  Handle cases with very short time spans (avoid division by zero).\n",
    "        time_span = max_timestamp - min_timestamp\n",
    "        if time_span > 0:\n",
    "            activity_rate = num_activities / (time_span/ (60*60*24) ) #per a day\n",
    "        else:\n",
    "            activity_rate = 0  # Or some other default value.\n",
    "\n",
    "        features.append([\n",
    "            profile_id,\n",
    "            degree,\n",
    "            in_degree,\n",
    "            out_degree,\n",
    "            clustering_coefficient,\n",
    "            #pagerank,\n",
    "            #betweenness,\n",
    "            good_neighbors,\n",
    "            num_activities,\n",
    "            activity_rate,\n",
    "        ])\n",
    "\n",
    "# --- Create a Pandas DataFrame for easier analysis ---\n",
    "\n",
    "feature_names = [\n",
    "    \"profile_id\",\n",
    "    \"degree\",\n",
    "    \"in_degree\",\n",
    "    \"out_degree\",\n",
    "    \"clustering_coefficient\",\n",
    "    #\"pagerank\",\n",
    "    #\"betweenness\",\n",
    "    \"good_neighbors\",\n",
    "    \"num_activities\",\n",
    "    \"activity_rate\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771b3414-369f-44e1-a33f-fe0b422e6e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/unknowit/miniconda3/envs/ML/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/unknowit/miniconda3/envs/ML/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/unknowit/miniconda3/envs/ML/lib/python3.11/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/unknowit/miniconda3/envs/ML/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/unknowit/miniconda3/envs/ML/lib/python3.11/site-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/unknowit/miniconda3/envs/ML/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd\n",
    "features_df = pd.DataFrame(features, columns=feature_names)\n",
    "\n",
    "# --- 3. Target Variable (Testing Period) ---\n",
    "\n",
    "# Create a set for efficient lookup\n",
    "bad_profile_ids_set = set(bad_profile_ids)\n",
    "targets = []\n",
    "\n",
    "# Check interaction in test graph\n",
    "for profile_id in profile_ids_list: #Loop through training profiles ids\n",
    "    interacted_with_bad = 0 # Target Variable\n",
    "    for edge in testing_graph.es:\n",
    "        source_vertex_index = edge.source\n",
    "        target_vertex_index = edge.target\n",
    "        # Check if source/target is the current profile\n",
    "        if testing_graph.vs[source_vertex_index][\"node_type\"] == \"profile\" and testing_graph.vs[source_vertex_index][\"original_id\"] == profile_id:\n",
    "            #Check if the interacting node is \"bad\", and of the right type.\n",
    "            if testing_graph.vs[target_vertex_index][\"node_type\"] == \"profile\" and testing_graph.vs[target_vertex_index][\"original_id\"] in bad_profile_ids_set:\n",
    "                interacted_with_bad = 1\n",
    "                break #No need\n",
    "        elif testing_graph.vs[target_vertex_index][\"node_type\"] == \"profile\" and testing_graph.vs[target_vertex_index][\"original_id\"] == profile_id:\n",
    "\n",
    "         if testing_graph.vs[source_vertex_index][\"node_type\"] == \"profile\" and testing_graph.vs[source_vertex_index][\"original_id\"] in bad_profile_ids_set:\n",
    "                interacted_with_bad = 1\n",
    "                break\n",
    "    targets.append(interacted_with_bad)\n",
    "\n",
    "# --- 4. Combine Features and Target ---\n",
    "features_df[\"interacted_with_bad\"] = targets # Add target variable\n",
    "\n",
    "# --- 5. Analysis and Correlation (Example) ---\n",
    "print(\"\\n--- Feature Statistics ---\")\n",
    "print(features_df.describe()) #summary stats\n",
    "\n",
    "print(\"\\n--- Correlation with Target Variable ---\")\n",
    "print(features_df.corr()[\"interacted_with_bad\"].sort_values(ascending=False)) #correlation\n",
    "\n",
    "# --- 6. Further Analysis and Visualization ---\n",
    "\n",
    "import matplotlib.pyplot as plt #import\n",
    "import seaborn as sns #import\n",
    "\n",
    "# Example: Box plots of features, separated by whether they interacted with a bad profile or not.\n",
    "for feature_name in feature_names:\n",
    "     if feature_name != 'profile_id':\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.boxplot(x=\"interacted_with_bad\", y=feature_name, data=features_df)\n",
    "        plt.title(f\"{feature_name} vs. Interaction with Bad Profiles\")\n",
    "        plt.show()\n",
    "\n",
    "#Scatter plot between good neighbours, and activity rate.\n",
    "plt.figure()\n",
    "sns.scatterplot(x = \"good_neighbors\", y = \"activity_rate\", hue = \"interacted_with_bad\", data = features_df)\n",
    "plt.show()\n",
    "# --- (Optional) Model Training ---\n",
    "# (You could use scikit-learn here to train a predictive model)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "#\n",
    "# # Split data (if you want to build a model - not strictly necessary for initial exploration)\n",
    "# X = features_df.drop([\"profile_id\", \"interacted_with_bad\"],axis = 1) # X = features\n",
    "# y = features_df[\"interacted_with_bad\"] # y = target\n",
    "# if len(X) > 0: # Make Sure that you have enough data to train model.\n",
    "  # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "  # # Train a model (example: Logistic Regression)\n",
    "  # model = LogisticRegression()\n",
    "  # model.fit(X_train, y_train)\n",
    "\n",
    "  #  # Make predictions\n",
    "  # y_pred = model.predict(X_test)\n",
    "\n",
    "  #  # Evaluate\n",
    "  # print(\"\\n--- Model Evaluation ---\")\n",
    "  # print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "  # print(classification_report(y_test, y_pred)) # Gives precision, recall, F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "892dae5c-5f02-4d01-84e0-145dc93790f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     40\u001b[39m     ig.plot(subgraph, **visual_style)\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43mplot_ego_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter_node_original_id\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m27059\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# --- 2. Induced Subgraph from Community Detection ---\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_community_subgraph\u001b[39m(graph, community_index):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mplot_ego_network\u001b[39m\u001b[34m(graph, center_node_original_id, radius)\u001b[39m\n\u001b[32m     25\u001b[39m subgraph = graph.subgraph(ego_network_vertices)\n\u001b[32m     27\u001b[39m   \u001b[38;5;66;03m# Choose a layout (kk is often good for smaller graphs)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m layout = \u001b[43msubgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayout\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mkk\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Basic visual styles (customize as needed)\u001b[39;00m\n\u001b[32m     31\u001b[39m visual_style = {\n\u001b[32m     32\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mvertex_label\u001b[39m\u001b[33m\"\u001b[39m: subgraph.vs[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     33\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mvertex_size\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m20\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmargin\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m50\u001b[39m,\n\u001b[32m     38\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.11/site-packages/igraph/layout.py:531\u001b[39m, in \u001b[36m_layout\u001b[39m\u001b[34m(graph, layout, *args, **kwds)\u001b[39m\n\u001b[32m    529\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(method):\n\u001b[32m    530\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mlayout method must be callable\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m layout = \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layout, Layout):\n\u001b[32m    533\u001b[39m     layout = Layout(layout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml/lib/python3.11/site-packages/igraph/layout.py:691\u001b[39m, in \u001b[36m_layout_method_wrapper.<locals>.result\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresult\u001b[39m(*args, **kwds):\n\u001b[32m--> \u001b[39m\u001b[32m691\u001b[39m     layout = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layout, Layout):\n\u001b[32m    693\u001b[39m         layout = Layout(layout)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- 1. Ego Network ---\n",
    "def plot_ego_network(graph, center_node_original_id, radius=2):\n",
    "    \"\"\"Plots the ego network of a given node.\n",
    "\n",
    "    Args:\n",
    "        graph: The igraph Graph object.\n",
    "        center_node_original_id: The original ID of the center node.\n",
    "        radius: The radius (distance from the center node) to include.\n",
    "    \"\"\"\n",
    "    center_vertex_index = None\n",
    "    for v in graph.vs:\n",
    "         if v[\"node_type\"] == \"profile\" and v[\"original_id\"] == center_node_original_id:\n",
    "            center_vertex_index = v.index\n",
    "            break  # Important: Exit the loop once found\n",
    "\n",
    "\n",
    "    if center_vertex_index is None:\n",
    "        print(f\"Error: Could not find node with original ID {center_node_original_id}\")\n",
    "        return\n",
    "\n",
    "    # Get the ego network (nodes within 'radius' distance)\n",
    "    ego_network_vertices = graph.neighborhood(center_vertex_index, order=radius)\n",
    "\n",
    "    # Create the induced subgraph\n",
    "    subgraph = graph.subgraph(ego_network_vertices)\n",
    "\n",
    "      # Choose a layout (kk is often good for smaller graphs)\n",
    "    layout = subgraph.layout(\"kk\")\n",
    "\n",
    "    # Basic visual styles (customize as needed)\n",
    "    visual_style = {\n",
    "        \"vertex_label\": subgraph.vs[\"name\"],\n",
    "        \"vertex_size\": 20,\n",
    "         \"vertex_color\": [\"skyblue\" if n[\"node_type\"] == \"profile\" else \"salmon\" for n in subgraph.vs],\n",
    "        \"layout\": layout,\n",
    "        \"bbox\": (600, 600),\n",
    "        \"margin\": 50,\n",
    "    }\n",
    "\n",
    "    ig.plot(subgraph, **visual_style)\n",
    "\n",
    "# Example usage:\n",
    "plot_ego_network(graph, center_node_original_id=27059, radius=2)\n",
    "\n",
    "\n",
    "\n",
    "# --- 2. Induced Subgraph from Community Detection ---\n",
    "def plot_community_subgraph(graph, community_index):\n",
    "    \"\"\"Plots the subgraph corresponding to a specific community.\n",
    "\n",
    "    Args:\n",
    "        graph: The igraph Graph object.\n",
    "        community_index: The index of the community to plot (0-based).\n",
    "    \"\"\"\n",
    "\n",
    "    # Run community detection (Louvain) - only run it *once* on the full graph\n",
    "    communities = graph.community_multilevel()  # Louvain\n",
    "    # communities = graph.community_leiden()  # Leiden (another good algorithm)\n",
    "\n",
    "    if community_index < 0 or community_index >= len(communities):\n",
    "        print(f\"Error: Invalid community index {community_index}.  Must be between 0 and {len(communities) - 1}\")\n",
    "        return\n",
    "\n",
    "\n",
    "    # Get the vertices belonging to the specified community\n",
    "    community_vertices = communities[community_index]\n",
    "\n",
    "\n",
    "    # Create an induced subgraph\n",
    "    subgraph = graph.subgraph(community_vertices)\n",
    "\n",
    "    # Layout and visual styles (customize as needed!)\n",
    "    layout = subgraph.layout(\"kk\")  # Or \"fr\"\n",
    "    visual_style = {\n",
    "        \"vertex_label\": subgraph.vs[\"name\"],\n",
    "        \"vertex_size\": 20,\n",
    "        \"vertex_color\": [\"skyblue\" if n[\"node_type\"] == \"profile\" else \"salmon\" for n in subgraph.vs],\n",
    "        \"layout\": layout,\n",
    "         \"bbox\": (600, 600),\n",
    "        \"margin\": 20,\n",
    "    }\n",
    "    ig.plot(subgraph, **visual_style)\n",
    "\n",
    "# Example usage:\n",
    "plot_community_subgraph(graph, community_index=0)  # Plot community 0\n",
    "# plot_community_subgraph(graph, community_index=2)  # Plot community 2\n",
    "\n",
    "\n",
    "def edge_sample(graph, num_edges):\n",
    "  \"\"\"Plot sample edges of graph.\n",
    "  Args:\n",
    "        graph: The igraph Graph object.\n",
    "        community_index: The index of the community to plot (0-based).\n",
    "  \"\"\"\n",
    "  random_edges = random.sample(graph.get_edgelist(), num_edges)\n",
    "  subgraph = graph.subgraph_edges(random_edges)\n",
    "\n",
    "      # Layout and visual styles (customize as needed!)\n",
    "  layout = subgraph.layout(\"kk\")  # Or \"fr\"\n",
    "  visual_style = {\n",
    "      \"vertex_label\": subgraph.vs[\"name\"],\n",
    "      \"vertex_size\": 20,\n",
    "      \"vertex_color\": [\"skyblue\" if n[\"node_type\"] == \"profile\" else \"salmon\" for n in subgraph.vs],\n",
    "      \"layout\": layout,\n",
    "        \"bbox\": (600, 600),\n",
    "      \"margin\": 20,\n",
    "  }\n",
    "  ig.plot(subgraph, **visual_style)\n",
    "#Example usage:\n",
    "print('\\nPLOTTING EDGE SAMPLE\\n')\n",
    "edge_sample(graph, 300)\n",
    "\n",
    "\n",
    "# # --- 3. Filtering by Degree/Centrality (Example with Degree) ---\n",
    "\n",
    "def plot_high_degree_subgraph(graph, top_n=50):\n",
    "    \"\"\"Plots a subgraph of the top 'n' nodes with the highest degree.\"\"\"\n",
    "\n",
    "    # Calculate degrees\n",
    "    degrees = graph.degree()\n",
    "\n",
    "    # Get the indices of the top 'n' nodes\n",
    "    top_node_indices = sorted(range(len(degrees)), key=lambda i: degrees[i], reverse=True)[:top_n]\n",
    "\n",
    "    # Create the induced subgraph\n",
    "    subgraph = graph.subgraph(top_node_indices)\n",
    "\n",
    "    # Layout and visual styles\n",
    "    layout = subgraph.layout(\"kk\")\n",
    "    visual_style = {\n",
    "        \"vertex_label\": subgraph.vs[\"name\"],\n",
    "        \"vertex_size\": [d * 2 for d in subgraph.degree()],  # Size proportional to degree\n",
    "        \"vertex_color\": [\"skyblue\" if n[\"node_type\"] == \"profile\" else \"salmon\" for n in subgraph.vs],\n",
    "        \"layout\": layout,\n",
    "        \"bbox\": (600, 600),\n",
    "        \"margin\": 20,\n",
    "    }\n",
    "    ig.plot(subgraph, **visual_style)\n",
    "\n",
    "\n",
    "print('\\nPLOTTING HIGH DEGREE SUBGRAPH\\n')\n",
    "plot_high_degree_subgraph(graph, top_n=50)\n",
    "\n",
    "\n",
    "\n",
    "# --- 4. Random Subsampling ---\n",
    "\n",
    "def plot_random_subgraph(graph, num_nodes=100):\n",
    "    \"\"\"Plots a random induced subgraph with a specified number of nodes.\"\"\"\n",
    "\n",
    "    if num_nodes > graph.vcount():\n",
    "        print(\"Error:  Cannot sample more nodes than exist in the graph.\")\n",
    "        return\n",
    "\n",
    "    # Randomly select node indices\n",
    "    sampled_node_indices = random.sample(range(graph.vcount()), num_nodes)\n",
    "\n",
    "    # Create the induced subgraph\n",
    "    subgraph = graph.subgraph(sampled_node_indices)\n",
    "     # Layout and visual styles\n",
    "    layout = subgraph.layout(\"kk\")  # Or \"fr\"\n",
    "    visual_style = {\n",
    "        \"vertex_label\": subgraph.vs[\"name\"],\n",
    "        \"vertex_size\": 20,\n",
    "        \"vertex_color\": [\"skyblue\" if n[\"node_type\"] == \"profile\" else \"salmon\" for n in subgraph.vs],\n",
    "        \"layout\": layout,\n",
    "        \"bbox\": (600, 600),\n",
    "        \"margin\": 20,\n",
    "    }\n",
    "    ig.plot(subgraph, **visual_style)\n",
    "\n",
    "print('\\nPLOTTING RANDOM SUBGRAPH\\n')\n",
    "plot_random_subgraph(graph, num_nodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a962c4f6-f636-40bb-803e-9e506c402f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
